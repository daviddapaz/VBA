{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DF_WC [ GWC, NWC, RF, EPT, DISC, availDISC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_nwc = '1.exportNWC_v2.xlsx'\n",
    "file_gwc = '1.exportGWC_v2.xlsx'\n",
    "file_alert = '_Alerts Data .xlsx'\n",
    "file_strat = 'all_strategy.xlsx'\n",
    "file_disc = 'discounting.xlsx'\n",
    "file_availdisc = 'Potential Discounting by contract.xlsx'\n",
    "\n",
    "file_pl = 'e931a Margin per ton v10.xlsx'\n",
    "file_strat = 'all_strategy.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gross Working Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gwc = pd.read_excel(file_gwc,converters={'Company Code': str,'Strategy ID': str })\n",
    "cols_gwc = list(df_gwc.columns)\n",
    "cols_gwc\n",
    "df_gwc.columns = cols_gwc[0:6] + [x[7:17] for x in cols_gwc[6:]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Net Working Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_nwc = pd.read_excel(file_nwc,converters={'Company Code': str,'Strategy ID': str })\n",
    "cols_nwc = list(df_nwc.columns)\n",
    "df_nwc.columns = cols_nwc[0:6] + [x[7:17] for x in cols_nwc[6:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Factoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rf = pd.read_excel(file_alert, sheetname='Rf data',converters={'Company Code': str,'Strategy ID': str })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_cols = list(df_gwc.columns[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculation of reverse factoring per day\n",
    "for date in date_cols:\n",
    "    df_rf[date] = np.where((df_rf['Original payment date'] <= datetime.strptime(date,'%d.%m.%Y')) &\n",
    "                              (df_rf['Amended Due Date'] > datetime.strptime(date,'%d.%m.%Y')),\n",
    "                             df_rf['Amount'],\n",
    "                             0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensuring that both data frames have the same columns\n",
    "cols_gwc = df_gwc.columns\n",
    "df_rf = df_rf[cols_gwc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Payment Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ext = pd.read_excel(file_alert, sheetname='DataNarlLukoil',converters={'Company Code': str,'Strategy': str })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# changing column labels\n",
    "list_cols = list(df_ext.columns)\n",
    "list_cols[3] = 'standard due date'\n",
    "list_cols[4] = 'number days'\n",
    "list_cols[13] = 'Strategy ID'\n",
    "list_cols[20] = 'category'\n",
    "list_cols[21] = 'weight'\n",
    "df_ext.columns = list_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filtering columns\n",
    "df_ext = df_ext.loc[:,'Delivery ID':'Internal type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill the extended payment terms per day\n",
    "for date in date_cols:\n",
    "    df_ext[date] = np.where((df_ext['FIN due date'] > datetime.strptime(date,'%d.%m.%Y')) &\n",
    "                              (df_ext['standard due date'] <= datetime.strptime(date,'%d.%m.%Y')) &\n",
    "                            (df_ext['In/Out'] == 'Sell') &\n",
    "                             (df_ext['Internal type'].isnull() == True) &\n",
    "                            (df_ext['number days'] > 0),\n",
    "                             df_ext['Final Amount']*-1,\n",
    "                             0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensuring that both data frames have the same columns\n",
    "df_ext = df_ext[cols_gwc]\n",
    "\n",
    "# replacing EUR by USD\n",
    "\n",
    "df_ext['Currency'] = 'USD'\n",
    "\n",
    "#df_ext = df_ext[cols_gwc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_disc = pd.read_excel(file_disc,converters={'Company code': str,'StrategyID': str })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# changing column labels\n",
    "list_cols_disc = list(df_disc.columns)\n",
    "list_cols_disc[2] = 'Company Code'\n",
    "list_cols_disc[6] = 'Global Book name'\n",
    "list_cols_disc[7] = 'Portfolio name'\n",
    "list_cols_disc[9] = 'Strategy ID'\n",
    "df_disc.columns = list_cols_disc\n",
    "df_disc['Currency'] = 'USD'\n",
    "df_disc['Global Book name'] = df_disc['Global Book name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill the discounting per day\n",
    "for date in date_cols:\n",
    "    df_disc[date] = np.where((df_disc['Value Date 2018'] <= datetime.strptime(date,'%d.%m.%Y')) &\n",
    "                              (df_disc['Due Date 2018'] > datetime.strptime(date,'%d.%m.%Y')),\n",
    "                             df_disc['WCR amount'],\n",
    "                             0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replacing Middle Distillates by DISTILLATES\n",
    "\n",
    "df_disc['Global Book name'] = np.where(df_disc['Global Book name'] == 'MIDDLE DISTILLATES',\n",
    "                                      'DISTILLATES', df_disc['Global Book name'])\n",
    "\n",
    "\n",
    "# replacing Naphta by NAPHTHA\n",
    "\n",
    "df_disc['Global Book name'] = np.where(df_disc['Global Book name'] == 'NAPHTA',\n",
    "                                      'NAPHTHA', df_disc['Global Book name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensuring that both data frames have the same columns\n",
    "df_disc = df_disc[cols_gwc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available Discounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_availdisc =  pd.read_excel(file_availdisc,sheetname='PotentialDisc',\n",
    "                              converters={'Company Code': str,'Strategy ID': str }, skiprows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row Labels                      int64\n",
       "Counterparty2                   int64\n",
       "Title transfer date    datetime64[ns]\n",
       "FIN due date           datetime64[ns]\n",
       "Delivery ID                    object\n",
       "Sum of Final Amount           float64\n",
       "Securitisation                  int64\n",
       "Initial Date           datetime64[ns]\n",
       "End Date               datetime64[ns]\n",
       "Days                            int64\n",
       "Value Date 2018        datetime64[ns]\n",
       "Due Date 2018          datetime64[ns]\n",
       "Calc                          float64\n",
       "Company Code                   object\n",
       "Global Book name               object\n",
       "Line of Business               object\n",
       "Portfolio name                 object\n",
       "Strategy ID                    object\n",
       "Currency                       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title transfer date and Fin due date need to be datetime type\n",
    "df_availdisc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill the discounting per day\n",
    "for date in date_cols:\n",
    "    df_availdisc[date] = np.where((df_availdisc['Value Date 2018'] <= datetime.strptime(date,'%d.%m.%Y')) &\n",
    "                              (df_availdisc['Due Date 2018'] > datetime.strptime(date,'%d.%m.%Y')) &\n",
    "                                  (df_availdisc['Sum of Final Amount'] < -10000000) &\n",
    "                                  (df_availdisc['Securitisation'] == 0) &\n",
    "                                  ((df_availdisc['FIN due date'] - df_availdisc['Title transfer date']).dt.days >=10),\n",
    "                             df_availdisc['Sum of Final Amount']*-1,\n",
    "                             0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensuring that both data frames have the same columns\n",
    "df_availdisc = df_availdisc[cols_gwc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_availdisc = df_availdisc.fillna(value = 0)\n",
    "df_availdisc = df_availdisc.groupby(['Strategy ID','Company Code','Global Book name',\n",
    "                                     'Line of Business','Portfolio name','Currency'])[date_cols].sum().reset_index()\n",
    "# ensuring that both data frames have the same columns - order\n",
    "df_availdisc = df_availdisc[cols_gwc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning NA's and groupby strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# removing sensitive case in GB\n",
    "df_gwc['Global Book name'] = df_gwc['Global Book name'].str.upper()\n",
    "df_nwc['Global Book name'] = df_nwc['Global Book name'].str.upper()\n",
    "df_rf['Global Book name'] = df_rf['Global Book name'].str.upper()\n",
    "df_ext['Global Book name'] = df_ext['Global Book name'].str.upper()\n",
    "df_disc['Global Book name'] = df_disc['Global Book name'].str.upper()\n",
    "df_availdisc['Global Book name'] = df_availdisc['Global Book name'].str.upper()\n",
    "\n",
    "\n",
    "# removing sensitive case in LOB\n",
    "df_gwc['Line of Business'] = df_gwc['Line of Business'].str.upper()\n",
    "df_nwc['Line of Business'] = df_nwc['Line of Business'].str.upper()\n",
    "df_rf['Line of Business'] = df_rf['Line of Business'].str.upper()\n",
    "df_ext['Line of Business'] = df_ext['Line of Business'].str.upper()\n",
    "df_disc['Line of Business'] = df_disc['Line of Business'].str.upper()\n",
    "df_availdisc['Line of Business'] = df_availdisc['Line of Business'].str.upper()\n",
    "\n",
    "\n",
    "# ensuring that all nan are replaced by zeros and groupby strategy\n",
    "\n",
    "# gwc\n",
    "df_gwc = df_gwc.fillna(value = 0)\n",
    "#df_gwc = df_gwc.groupby(['Strategy ID','Company Code','Global Book name',\n",
    "#                                     'Line of Business','Portfolio name','Currency'])[date_cols].sum().reset_index()\n",
    "df_gwc = df_gwc[cols_gwc]\n",
    "\n",
    "# nwc\n",
    "df_nwc = df_nwc.fillna(value = 0)\n",
    "#df_nwc = df_nwc.groupby(['Strategy ID','Company Code','Global Book name',\n",
    "#                                     'Line of Business','Portfolio name','Currency'])[date_cols].sum().reset_index()\n",
    "df_nwc = df_nwc[cols_gwc]\n",
    "\n",
    "\n",
    "# rf\n",
    "df_rf = df_rf.fillna(value = 0)\n",
    "#df_rf = df_rf.groupby(['Strategy ID','Company Code','Global Book name',\n",
    "#                                     'Line of Business','Portfolio name','Currency'])[date_cols].sum().reset_index()\n",
    "df_rf = df_rf[cols_gwc]\n",
    "\n",
    "# ext\n",
    "df_ext = df_ext.fillna(value = 0)\n",
    "#df_ext = df_ext.groupby(['Strategy ID','Company Code','Global Book name',\n",
    "#                                     'Line of Business','Portfolio name','Currency'])[date_cols].sum().reset_index()\n",
    "df_ext = df_ext[cols_gwc]\n",
    "\n",
    "# disc\n",
    "df_disc = df_disc.fillna(value = 0)\n",
    "#df_disc = df_disc.groupby(['Strategy ID','Company Code','Global Book name',\n",
    "#                                     'Line of Business','Portfolio name','Currency'])[date_cols].sum().reset_index()\n",
    "df_disc = df_disc[cols_gwc]\n",
    "\n",
    "# availdisc\n",
    "df_availdisc = df_availdisc.fillna(value = 0)\n",
    "#df_availdisc = df_availdisc.groupby(['Strategy ID','Company Code','Global Book name',\n",
    "#                                     'Line of Business','Portfolio name','Currency'])[date_cols].sum().reset_index()\n",
    "df_availdisc = df_availdisc[cols_gwc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Securitization (not active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_nwc_negative = df_nwc.copy()\n",
    "#s = df_nwc_negative.select_dtypes(include=[np.number])*-1\n",
    "#df_nwc_negative[s.columns] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_disc_negative = df_disc.copy()\n",
    "#s = df_disc_negative.select_dtypes(include=[np.number])*-1\n",
    "#df_disc_negative[s.columns] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# groupby: SECU = GWC - NWC - DISC\n",
    "#df_secu = pd.concat([df_gwc, df_nwc_negative, df_disc_negative])\n",
    "#df_secu = df_secu.fillna(value = 0)\n",
    "\n",
    "#df_secu['Global Book name'] = df_secu['Global Book name'].str.upper()\n",
    "#df_secu['Line of Business'] = df_secu['Line of Business'].str.upper()\n",
    "\n",
    "#df_secu = df_secu.groupby(['Strategy ID','Company Code','Global Book name',\n",
    "#                                     'Line of Business','Portfolio name','Currency'])[date_cols].sum().reset_index()\n",
    "#df_secu = df_secu[cols_gwc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# add category to each dataframe\n",
    "df_gwc['Category'] = 'GWC'\n",
    "df_nwc['Category'] = 'NWC'\n",
    "df_rf['Category'] = 'RF'\n",
    "df_ext['Category'] = 'EPT'\n",
    "df_disc['Category'] = 'DISC'\n",
    "df_availdisc['Category'] = 'AvailDISC'\n",
    "#df_secu['Category'] = 'SECU'\n",
    "\n",
    "# send the last column to the first\n",
    "df_gwc = df_gwc.set_index('Category').reset_index()\n",
    "df_nwc = df_nwc.set_index('Category').reset_index()\n",
    "df_rf = df_rf.set_index('Category').reset_index()\n",
    "df_ext = df_ext.set_index('Category').reset_index()\n",
    "df_disc = df_disc.set_index('Category').reset_index()\n",
    "df_availdisc = df_availdisc.set_index('Category').reset_index()\n",
    "#df_secu = df_secu.set_index('Category').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concatenating the dataframes\n",
    "df_wc = pd.concat([df_gwc, df_nwc, df_rf, df_ext, df_disc, df_availdisc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Efficiency reports portfolio adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strat = pd.read_excel(file_strat, dtype=str)\n",
    "\n",
    "# create a column with portfolio add-ons\n",
    "strat['Portfolio_adj1'] = strat['Portfolio name']\n",
    "\n",
    "\n",
    "# Strategies containing \"NICO\" on \"T-Feed\"portfolio are assigned to Portfolio \"T-Feed NICO\"\n",
    "\n",
    "strat['Portfolio_adj1'] = np.where((strat['Strategy name'].str.contains('NICO') == True) & (strat['Portfolio name'] == 'T-Feed'),\n",
    "                                  'T-Feed NICO', strat['Portfolio_adj1'])\n",
    "\n",
    "\n",
    "# Books containing \"T-Feed Storages\" on \"T-Feed\" Portfolio are assigned to Portfolio \"T-Feed Storage\"\n",
    "\n",
    "strat['Portfolio_adj1'] = np.where((strat['Book Name'].str.contains('T-Feed Storages') == True) & (strat['Portfolio name'] == 'T-Feed'),\n",
    "                                  'T-Feed Storage', strat['Portfolio_adj1'])\n",
    "\n",
    "\n",
    "# Books containing \"T-Feed US ARB\" on \"T-Feed\" Portfolio are assigned to Portfolio \"T-Feed US ARB\"\n",
    "\n",
    "strat['Portfolio_adj1'] = np.where((strat['Book Name'].str.contains('T-Feed US ARB') == True) & (strat['Portfolio name'] == 'T-Feed'),\n",
    "                                  'T-Feed US ARB', strat['Portfolio_adj1'])\n",
    "\n",
    "\n",
    "# Portfolios \"Term Contract\" and \"Term Contracts\" on \"DISTILLATES\" Global Book are assigned to Portfolio \"Storages NWE ULSD\"\n",
    "\n",
    "strat['Portfolio_adj1'] = np.where((strat['Global Book name'] == 'DISTILLATES') & (strat['Portfolio name'].str.contains('Term Contract')),\n",
    "                                  'Storages NWE ULSD', strat['Portfolio_adj1'])\n",
    "\n",
    "\n",
    "# Portfolio \"T-Feed Paper\" on \"0100\" Company Code are assigned to Portfolio \"T-Feed Cargoes\"\n",
    "\n",
    "strat['Portfolio_adj1'] = np.where((strat['Company code'] == '0100') & (strat['Portfolio name'] == 'T-Feed Paper'),\n",
    "                                  'T-Feed Cargoes', strat['Portfolio_adj1'])\n",
    "\n",
    "\n",
    "# Portfolio adj \"T-Feed\" on \"0100\" Company Code are assigned to Portfolio \"T-Feed Cargoes\"\n",
    "\n",
    "strat['Portfolio_adj1'] = np.where((strat['Company code'] == '0100') & (strat['Portfolio_adj1'] == 'T-Feed'),\n",
    "                                  'T-Feed Cargoes', strat['Portfolio_adj1'])\n",
    "\n",
    "\n",
    "# Line of business LAP Cracked into Portfolio \"T-Cracked East ARB\"\n",
    "\n",
    "strat['Portfolio_adj1'] = np.where(strat['Line of Business'] == 'LAP Cracked',\n",
    "                                  'T-Cracked East ARB', strat['Portfolio_adj1'])\n",
    "\n",
    "\n",
    "\n",
    "#send portfolios to margin calls/costs/unassigned based on arguments\n",
    "\n",
    "strat['Portfolio_adj2'] = strat['Portfolio_adj1'].str.lower()\n",
    "strat['Portfolio_adj2'] = np.where((strat['Portfolio_adj2'].str.contains('term contract')) \n",
    "                         | (strat['Portfolio_adj2'].str.contains('paper'))\n",
    "                         | (strat['Portfolio_adj2'].str.contains('cost'))          \n",
    "                         | (strat['Portfolio_adj2'].str.contains('emission'))                   \n",
    "                         | (strat['Portfolio_adj2'].str.contains('default'))                   \n",
    "                         | (strat['Portfolio_adj2'].str.contains('derivative'))\n",
    "                         | (strat['Portfolio_adj2'].str.contains('intel'))\n",
    "                         | (strat['Portfolio_adj2'].str.contains('hedg'))\n",
    "                         | (strat['Portfolio_adj2'].str.contains('accounting'))          \n",
    "                         | (strat['Portfolio_adj2'].str.contains('forward'))                    \n",
    "                         ,strat['Global Book name'] + ' Margin Call/Paper/Costs', strat['Portfolio_adj1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set index in strat so we can do the vlookup/map\n",
    "strat = strat.set_index('Strategy')\n",
    "\n",
    "# assign the adjusted portfolios to working capital data\n",
    "df_wc['Portfolio_ER'] = df_wc['Strategy ID'].map(strat['Portfolio_adj2'])\n",
    "\n",
    "# set and reset index so the new column does not stay at the right\n",
    "df_wc = df_wc.set_index('Portfolio_ER')\n",
    "df_wc = df_wc.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 'GVA Crude Oil Accounting', 'GVA Distillates Accounting', 'GVA Gasoline Accounting', 'GVA Cracked Accounting', 'GVA Naphtha Accounting', 'LAP Crude Accounting', 'LAP Distillates Accounting', 'LAP Gasoline Accounting', 'LAP Cracked Accounting', 'LAP Naphtha Accounting', 'LME Distillates Accounting', 'LPA Crude Accounting', 'NARL REFINING', 'LPA Distillates Accounting', 'LPA USGC Blending Accounting', 'LPA Naphtha Accounting']\n"
     ]
    }
   ],
   "source": [
    "# list portfolios to allocate\n",
    "\n",
    "print(list(df_wc[df_wc['Strategy ID'] == '0']['Portfolio name'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjustments of portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all in company \"0600\" goes to \"Naphtha\"\n",
    "df_wc['Portfolio_ER'] = np.where(df_wc['Company Code'] == '0600','Naphtha', df_wc['Portfolio_ER'])\n",
    "\n",
    "# company \"0700\" in DISTILLATES to LBBV Storages\n",
    "df_wc['Portfolio_ER'] = np.where((df_wc['Company Code'] == '0700') &\n",
    "                                  (df_wc['Global Book name'] == 'DISTILLATES'), 'LBBV Storages',\n",
    "                                  df_wc['Portfolio_ER'])\n",
    "\n",
    "# company \"0700\" in HEAVY to LBBV Physical Portfolio\n",
    "df_wc['Portfolio_ER'] = np.where((df_wc['Company Code'] == '0700') &\n",
    "                                  (df_wc['Global Book name'] == 'HEAVY'), 'Physical Portfolio',\n",
    "                                  df_wc['Portfolio_ER'])\n",
    "\n",
    "\n",
    "# portfolio name \"Storages MED\" in DISTILLATES\n",
    "df_wc['Portfolio_ER'] = np.where((df_wc['Strategy ID'] == '0') &\n",
    "                                 (df_wc['Global Book name'] == 'DISTILLATES') &\n",
    "                                 (df_wc['Portfolio name'] == 'Storages MED'),'Storages MED',\n",
    "                                 df_wc['Portfolio_ER'])\n",
    "\n",
    "\n",
    "# portfolio name \"NARL REFINING\" to NARL REFINING\n",
    "df_wc['Portfolio_ER'] = np.where((df_wc['Strategy ID'] == '0') &\n",
    "                                 (df_wc['Portfolio name'] == 'NARL REFINING'),'NARL REFINING',\n",
    "                                 df_wc['Portfolio_ER'])\n",
    "\n",
    "\n",
    "# all the remaining are assigned to \"Global Book name\" + \" Margin Call/Paper/Costs\n",
    "df_wc['Portfolio_ER'] = np.where(df_wc['Portfolio_ER'].isnull() == True,\n",
    "                                  df_wc['Global Book name'].astype(str) + ' Margin Call/Paper/Costs',\n",
    "                                 df_wc['Portfolio_ER'])\n",
    "\n",
    "# Euroeco fuels\n",
    "df_wc['Portfolio_ER'] = np.where((df_wc['Strategy ID'] == '505369') |\n",
    "                                 (df_wc['Strategy ID'] == '509185') &\n",
    "                                 (df_wc['Global Book name'] == 'HEAVY'),'EUROECO FUELS',\n",
    "                                 df_wc['Portfolio_ER'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the JV's from Global Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# JV's\n",
    "\n",
    "df_wc['Global Book name'] = np.where(df_wc['Line of Business'].str.contains('IPT') == True,\n",
    "                                    'JVs',\n",
    "                                    df_wc['Global Book name'])\n",
    "\n",
    "df_wc['Global Book name'] = np.where(df_wc['Line of Business'].str.contains('NARL') == True,\n",
    "                                    'JVs',\n",
    "                                    df_wc['Global Book name'])\n",
    "\n",
    "df_wc['Global Book name'] = np.where(df_wc['Line of Business'].str.contains('GNPC') == True,\n",
    "                                    'JVs',\n",
    "                                    df_wc['Global Book name'])\n",
    "\n",
    "df_wc['Global Book name'] = np.where(df_wc['Line of Business'].str.contains('MRS JV') == True,\n",
    "                                    'JVs',\n",
    "                                    df_wc['Global Book name'])\n",
    "\n",
    "df_wc['Global Book name'] = np.where(df_wc['Portfolio name'].str.contains('FalconRain') == True,\n",
    "                                    'JVs',\n",
    "                                    df_wc['Global Book name'])\n",
    "\n",
    "df_wc['Global Book name'] = np.where(df_wc['Portfolio_ER'] == 'EUROECO FUELS',\n",
    "                                    'JVs',\n",
    "                                    df_wc['Global Book name'])\n",
    "\n",
    "\n",
    "df_wc['Global Book name'] = np.where(df_wc['Line of Business'] == 'LPA BASF HEDGE',\n",
    "                                    'JVs',\n",
    "                                    df_wc['Global Book name'])\n",
    "\n",
    "df_wc['Portfolio_ER'] = np.where(df_wc['Line of Business'] == 'LPA BASF HEDGE',\n",
    "                                    df_wc['Portfolio name'],\n",
    "                                    df_wc['Portfolio_ER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 Margin Call/Paper/Costs', 'ASSET TRADING Margin Call/Paper/Costs', 'CRUDE Margin Call/Paper/Costs', 'DERIVATIVES Margin Call/Paper/Costs', 'DISTILLATES Margin Call/Paper/Costs', 'GASOLINE Margin Call/Paper/Costs', 'HEAVY Margin Call/Paper/Costs', 'NAPHTHA Margin Call/Paper/Costs', 'OTHER Margin Call/Paper/Costs', 'PETCHEM Margin Call/Paper/Costs', 'REFINING Margin Call/Paper/Costs', 'LCA Margin Call/Paper/Costs', 'Naphtha', 'LBBV Storages', 'Physical Portfolio', 'ACCOUNTING Margin Call/Paper/Costs', 'NARL REFINING']\n"
     ]
    }
   ],
   "source": [
    "# list portfolios to allocate\n",
    "\n",
    "print(list(df_wc[df_wc['Strategy ID'] == '0']['Portfolio_ER'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add book-key column\n",
    "\n",
    "df_wc['Book - Key'] = df_wc['Strategy ID'].map(strat['Book - Key'])\n",
    "df_wc.set_index('Book - Key', inplace=True)\n",
    "df_wc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export data\n",
    "\n",
    "\n",
    "# Month\n",
    "\n",
    "#df_wc['JAN_avg'] = df_wc.loc[:,'01.01.2018':'31.01.2018'].mean(axis=1)\n",
    "#df_wc['FEB_avg'] = df_wc.loc[:,'01.02.2018':'28.02.2018'].mean(axis=1)\n",
    "#df_wc['MAR_avg'] = df_wc.loc[:,'01.03.2018':'31.03.2018'].mean(axis=1)\n",
    "\n",
    "# YTD by month\n",
    "#df_wc['JAN_avg_YTD'] = df_wc.loc[:,'01.01.2018':'31.01.2018'].mean(axis=1)\n",
    "#df_wc['FEB_avg_YTD'] = df_wc.loc[:,'01.01.2018':'28.02.2018'].mean(axis=1)\n",
    "#df_wc['MAR_avg_YTD'] = df_wc.loc[:,'01.01.2018':'31.03.2018'].mean(axis=1)\n",
    "\n",
    "# Quarter\n",
    "#df_wc['Q1_avg'] = df_wc.loc[:,'01.01.2018':'31.03.2018'].mean(axis=1)\n",
    "\n",
    "# YTD\n",
    "#df_wc['YTD_avg'] = df_wc.loc[:,'01.01.2018':'24.04.2018'].mean(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#writer = pd.ExcelWriter('database_wc.xlsx')\n",
    "#df_wc.to_excel(writer, 'data_wc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_wc_er = df_wc.copy()\n",
    "\n",
    "# divide the numerical columns (date columns) by 1000000\n",
    "df_wc_er[date_cols] = df_wc_er[date_cols]/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# groupby portfolio\n",
    "\n",
    "#df_wc_er = df_wc_er.groupby(['Book - Key','Portfolio_ER','Category','Company Code','Global Book name',\n",
    "#                                     'Line of Business','Portfolio name','Currency'])[date_cols].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Month\n",
    "\n",
    "df_wc_er['JAN_avg'] = df_wc_er.loc[:,'01.01.2018':'31.01.2018'].mean(axis=1)\n",
    "df_wc_er['FEB_avg'] = df_wc_er.loc[:,'01.02.2018':'28.02.2018'].mean(axis=1)\n",
    "df_wc_er['MAR_avg'] = df_wc_er.loc[:,'01.03.2018':'31.03.2018'].mean(axis=1)\n",
    "df_wc_er['APR_avg'] = df_wc_er.loc[:,'01.04.2018':'30.04.2018'].mean(axis=1)\n",
    "df_wc_er['MAY_avg'] = df_wc_er.loc[:,'01.05.2018':'31.05.2018'].mean(axis=1)\n",
    "df_wc_er['JUN_avg'] = df_wc_er.loc[:,'01.06.2018':'30.06.2018'].mean(axis=1)\n",
    "\n",
    "# YTD by month\n",
    "df_wc_er['JAN_avg_YTD'] = df_wc_er.loc[:,'01.01.2018':'31.01.2018'].mean(axis=1)\n",
    "df_wc_er['FEB_avg_YTD'] = df_wc_er.loc[:,'01.01.2018':'28.02.2018'].mean(axis=1)\n",
    "df_wc_er['MAR_avg_YTD'] = df_wc_er.loc[:,'01.01.2018':'31.03.2018'].mean(axis=1)\n",
    "df_wc_er['APR_avg_YTD'] = df_wc_er.loc[:,'01.01.2018':'30.04.2018'].mean(axis=1)\n",
    "df_wc_er['MAY_avg_YTD'] = df_wc_er.loc[:,'01.01.2018':'31.05.2018'].mean(axis=1)\n",
    "df_wc_er['JUN_avg_YTD'] = df_wc_er.loc[:,'01.01.2018':'30.06.2018'].mean(axis=1)\n",
    "\n",
    "# Quarter\n",
    "df_wc_er['Q1_avg'] = df_wc_er.loc[:,'01.01.2018':'31.03.2018'].mean(axis=1)\n",
    "df_wc_er['Q2_avg'] = df_wc_er.loc[:,'01.04.2018':'30.06.2018'].mean(axis=1)\n",
    "\n",
    "\n",
    "# YTD\n",
    "df_wc_er['YTD_avg'] = df_wc_er.loc[:,'01.01.2018':'30.06.2018'].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter data\n",
    "#df_wc_er = df_wc_er.loc[(df_wc_er['Global Book name'] == 'CRUDE') |\n",
    "#                       (df_wc_er['Global Book name'] == 'HEAVY') |\n",
    "#                       (df_wc_er['Global Book name'] == 'DISTILLATES') |\n",
    "#                       (df_wc_er['Global Book name'] == 'GASOLINE') |\n",
    "#                       (df_wc_er['Global Book name'] == 'NAPHTHA') |\n",
    "#                       (df_wc_er['Global Book name'] == 'JVs')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export data\n",
    "\n",
    "#writer = pd.ExcelWriter('database_portfolio.xlsx')\n",
    "#df_wc_er.to_excel(writer, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_pl = 'e931a Margin per ton v10.xlsx'\n",
    "#file_strat = 'all_strategy.xlsx'\n",
    "strat.reset_index(inplace=True)\n",
    "\n",
    "# import pl\n",
    "df_pl = pd.read_excel(file_pl, sheetname='e931a PL by books(historical)', skiprows=5)\n",
    "\n",
    "# import strat\n",
    "#strat = pd.read_excel(file_strat, dtype=str)\n",
    "\n",
    "# replacing nan by zero\n",
    "\n",
    "df_pl.fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "# deleting all the rows containing total and drop them\n",
    "\n",
    "condition1 = df_pl[df_pl['Global Book'].str.contains('Total') == True]\n",
    "df_pl.drop(condition1.index, inplace=True)\n",
    "\n",
    "\n",
    "# deleting all rows with Global Book and drop them\n",
    "\n",
    "condition2 = df_pl[df_pl['Global Book'] == 'Global Book']\n",
    "\n",
    "df_pl.drop(condition2.index, inplace = True)\n",
    "\n",
    "\n",
    "# filter columns\n",
    "\n",
    "df_pl = df_pl[['MST','Book - Key', 'Adj Amount, USD']]\n",
    "\n",
    "\n",
    "# change columns name\n",
    "\n",
    "df_pl.columns = ['MST','Book - Key', 'YTD']\n",
    "df_pl['YTD'] = df_pl['YTD']/1000000\n",
    "\n",
    "# mapping\n",
    "\n",
    "df_pl['Company Code'] = df_pl['Book - Key'].map(\n",
    "    strat.drop_duplicates(subset='Book - Key').set_index('Book - Key')['Company code'])\n",
    "\n",
    "\n",
    "df_pl['Global Book name'] = df_pl['Book - Key'].map(\n",
    "    strat.drop_duplicates(subset='Book - Key').set_index('Book - Key')['Global Book name'])\n",
    "\n",
    "df_pl['Global Book name'] = df_pl['Global Book name'].str.upper()\n",
    "\n",
    "df_pl['Line of Business'] = df_pl['Book - Key'].map(\n",
    "    strat.drop_duplicates(subset='Book - Key').set_index('Book - Key')['Line of Business'])\n",
    "\n",
    "df_pl['Line of Business'] = df_pl['Line of Business'].str.upper()\n",
    "\n",
    "df_pl['Portfolio name'] = df_pl['Book - Key'].map(\n",
    "    strat.drop_duplicates(subset='Book - Key').set_index('Book - Key')['Portfolio name'])\n",
    "\n",
    "df_pl['Currency'] = 'USD'\n",
    "\n",
    "#df_pl['Category'] = 'PL'\n",
    "\n",
    "df_pl['Portfolio_ER'] = df_pl['Book - Key'].map(strat.drop_duplicates(subset='Book - Key').set_index('Book - Key')['Portfolio_adj2'])\n",
    "\n",
    "\n",
    "\n",
    "col_order = ['Book - Key','Portfolio_ER','MST','Company Code','Global Book name',\n",
    "             'Line of Business','Portfolio name', 'Currency','YTD']\n",
    "\n",
    "\n",
    "df_pl = df_pl[col_order]\n",
    "\n",
    "\n",
    "# filter data\n",
    "#df_pl = df_pl.loc[(df_pl['Global Book name'] == 'CRUDE') |\n",
    "#                       (df_pl['Global Book name'] == 'HEAVY') |\n",
    "#                       (df_pl['Global Book name'] == 'DISTILLATES') |\n",
    "#                       (df_pl['Global Book name'] == 'GASOLINE') |\n",
    "#                       (df_pl['Global Book name'] == 'NAPHTHA')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export Working Capital and PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WC is average, PL is sum\n",
    "\n",
    "# export data\n",
    "\n",
    "writer = pd.ExcelWriter('efficiency_data_all v2.xlsx')\n",
    "df_wc_er.to_excel(writer, 'data_wc', index=False)\n",
    "df_pl.to_excel(writer, 'data_pl', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
